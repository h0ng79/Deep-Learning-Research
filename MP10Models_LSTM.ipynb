{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L01vG6fjwF8"
      },
      "source": [
        "## Connect Driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAWO4VF9jtbd",
        "outputId": "92368da7-d2b6-483f-82c8-1133d8c7362e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZWBrMAvj770"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/Research/Deep Learning/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSC29AdXkBbj"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuggShLCin0x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import json\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import SGD, Adagrad, RMSprop, Adam, Adadelta, Adamax,Nadam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import timeit\n",
        "from keras.callbacks import CSVLogger\n",
        "import multiprocessing as mp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPwh61bNkzRz"
      },
      "source": [
        "##optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjnsnIzIkxj9"
      },
      "outputs": [],
      "source": [
        "adam = Adam(learning_rate=0.08, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "rms = RMSprop(learning_rate = 0.01, rho=0.9, epsilon=1e-08)\n",
        "ada = Adagrad(learning_rate=0.2, epsilon=1e-08)\n",
        "sgd = SGD(learning_rate=0.1, momentum=0.1)\n",
        "adadel=Adadelta(learning_rate=1.0, rho=0.95, epsilon=1e-08)\n",
        "adamax = Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
        "nadam = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmPV50SKjHtF"
      },
      "source": [
        "##Models 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGlGoW8tjB7k"
      },
      "outputs": [],
      "source": [
        "def LSTM_1(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"PReLU\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(50, activation=\"PReLU\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research/Deep Learning/LSTM/model_PReLU_adam.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=adam,metrics=['accuracy'])\n",
        "\n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research/Deep Learning/LSTM/training_history_PReLU_adam.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=1000, batch_size=32, verbose=2,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research/Deep Learning/LSTM/target_weight_PReLU_adam.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research/Deep Learning/LSTM/MSE_Computingtime_PReLU_adam.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cChO4MUDntjD"
      },
      "source": [
        "#Models 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELmNMqeanxJD"
      },
      "outputs": [],
      "source": [
        "def LSTM_2(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"PReLU\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(50, activation=\"PReLU\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research/Deep Learning/LSTM/model_PReLU_rms.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=rms,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research/Deep Learning/LSTM/training_history_PReLU_rms.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=1000, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research/Deep Learning/LSTM/target_weight_PReLU_rms.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research/Deep Learning/LSTM/MSE_Computingtime_PReLU_rms.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0D6PCEJn7rL"
      },
      "source": [
        "#Models3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvAWFxN6n-9a"
      },
      "outputs": [],
      "source": [
        "def LSTM_3(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"PReLU\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(50, activation=\"PReLU\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research/Deep Learning/LSTM/model_PReLU_ada.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=ada,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research/Deep Learning/LSTM/training_history_PReLU_ada.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=1000, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research/Deep Learning/LSTM/target_weight_PReLU_ada.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research/Deep Learning/LSTM/MSE_Computingtime_PReLU_ada.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r841pXBdoJ1D"
      },
      "source": [
        "#Models 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-h0yDvyoN3q"
      },
      "outputs": [],
      "source": [
        "def LSTM_4(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"PReLU\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(50, activation=\"PReLU\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research/Deep Learning/LSTM/model_PReLU_sgd.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=sgd,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research/Deep Learning/LSTM/training_history_PReLU_sgd.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=1000, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research/Deep Learning/LSTM/target_weight_PReLU_sgd.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research/Deep Learning/LSTM/MSE_Computingtime_PReLU_sgd.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooK7Fa59oTma"
      },
      "source": [
        "#Models 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbmPv68roW67"
      },
      "outputs": [],
      "source": [
        "def LSTM_5(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"PReLU\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(50, activation=\"PReLU\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research/Deep Learning/LSTM/model_PReLU_adadel.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=adadel,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research/Deep Learning/LSTM/training_history_PReLU_adadel.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=1000, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research/Deep Learning/LSTM/target_weight_PReLU_adadel.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research/Deep Learning/LSTM/MSE_Computingtime_PReLU_adadel.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SZ9pvKiogtD"
      },
      "source": [
        "#Models 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsCaML9Boi1T"
      },
      "outputs": [],
      "source": [
        "def LSTM_6(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"PReLU\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(50, activation=\"PReLU\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research/Deep Learning/LSTM/model_PReLU_adamax.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=adamax,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research/Deep Learning/LSTM/training_history_PReLU_adamax.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=1000, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research/Deep Learning/LSTM/target_weight_PReLU_adamax.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research/Deep Learning/LSTM/MSE_Computingtime_PReLU_adamax.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeWwoSFjorua"
      },
      "source": [
        "#Models 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3RjIEOGoq-S"
      },
      "outputs": [],
      "source": [
        "def LSTM_7(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"PReLU\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"PReLU\"))\n",
        "    model.add(LSTM(50, activation=\"PReLU\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research/Deep Learning/LSTM/model_PReLU_nadam.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=nadam,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research/Deep Learning/LSTM/training_history_PReLU_nadam.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=1000, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research/Deep Learning/LSTM/target_weight_PReLU_nadam.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research/Deep Learning/LSTM/MSE_Computingtime_PReLU_nadam.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPlobMAusRk7"
      },
      "source": [
        "#softplus1-7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBIRufausZNa"
      },
      "source": [
        "#Tanh 8-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAPnfYsXo2Lb"
      },
      "source": [
        "#Models 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6EljGDro39C"
      },
      "outputs": [],
      "source": [
        "def LSTM_8(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"tanh\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"tanh\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"tanh\"))\n",
        "    model.add(LSTM(50, activation=\"tanh\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research MU/LSTM/model_LP8.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=adam,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research MU/LSTM/training_history_dj8.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research MU/LSTM/target_weight8.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research MU/LSTM/MSE_Computingtime8.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24e1Pxxio_ES"
      },
      "source": [
        "#Models 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9f8TskfpB5K"
      },
      "outputs": [],
      "source": [
        "def LSTM_9(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"tanh\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"tanh\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"tanh\"))\n",
        "    model.add(LSTM(50, activation=\"tanh\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research MU/LSTM/model_LP9.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=rms,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research MU/LSTM/training_history_dj9.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research MU/LSTM/target_weight9.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research MU/LSTM/MSE_Computingtime9.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkbyavSppJaE"
      },
      "source": [
        "#Models 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgfoG-WapPQ7"
      },
      "outputs": [],
      "source": [
        "def LSTM_10(input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test):\n",
        "  # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, return_sequences=True,input_shape=(input_node,n_timesteps), activation=\"tanh\"))\n",
        "    model.add(LSTM(200, return_sequences=True,activation=\"tanh\"))\n",
        "    model.add(LSTM(100, return_sequences=True,activation=\"tanh\"))\n",
        "    model.add(LSTM(50, activation=\"tanh\"))\n",
        "    model.add(Dense(output_node))\n",
        "    model.summary()\n",
        "    json_string = model.to_json()\n",
        "    open('/content/drive/MyDrive/Research MU/LSTM/model_LP10.json', 'w').write(json_string)\n",
        "    \n",
        "    # fit network\n",
        "    model.compile(loss='mean_squared_error', optimizer=ada,metrics=['accuracy'])\n",
        "    \n",
        "    csv_logger = CSVLogger('/content/drive/MyDrive/Research MU/LSTM/training_history_dj10.csv')\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=1,callbacks=[csv_logger]) \n",
        "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "    model.save_weights('/content/drive/MyDrive/Research MU/LSTM/target_weight10.h5', overwrite=True)\n",
        "    \n",
        "    # Evaluation metrics\n",
        "    pred_train = model.predict(x_train)\n",
        "    pred_test = model.predict(x_test)\n",
        "    mse_train = mean_squared_error(y_train,pred_train)\n",
        "    mse_test  = mean_squared_error(y_test,pred_test)\n",
        "    mae_train = mean_absolute_error(y_train,pred_train)\n",
        "    mae_test = mean_absolute_error(y_test,pred_test)\n",
        "    r2_train = r2_score(y_train,pred_train)\n",
        "    r2_test = r2_score(y_test,pred_test)\n",
        "\n",
        "    #stop = timeit.default_timer()\n",
        "    with open(\"/content/drive/MyDrive/Research MU/LSTM/MSE_Computingtime10.txt\", \"w\") as text_file:\n",
        "        #print(\"Computing time: \"+str(stop - start), file=text_file)\n",
        "        print('MSE for train: ' +str(mse_train),file=text_file)\n",
        "        print('MSE for test: '  + str(mse_test), file=text_file)\n",
        "        print('mean absolute error for train: '+str(mae_train),file=text_file)\n",
        "        print('mean absolute error for test: ' + str(mae_test), file=text_file)\n",
        "        print('r2 score for train:' +str(r2_train),file=text_file)\n",
        "        print('r2 score for test: ' +str(r2_test),file=text_file)\n",
        "        print('scores: ' +str(scores),file=text_file)\n",
        "        print(\"%s:%.2f%%\" % (model.metrics_names[1], scores[1] * 100),file=text_file)\n",
        "\n",
        "\n",
        "    #print('Computing time:',stop - start)\n",
        "    print('mean square error for train and test',mse_train, mse_test)\n",
        "    print('mean absoliute error for train and test', mae_train,mae_test)\n",
        "    print('r2 score for train and test', r2_train,r2_test)\n",
        "    print('scores ',scores)\n",
        "    print(\"%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tR-avOMpXNL"
      },
      "source": [
        "# Set Fn Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r0gaTXC-pfOL"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  start = timeit.default_timer()\n",
        "  dataframe = pd.read_csv(path+'LaminatedPlate_RZT_Q9.csv')\n",
        "  dataset = dataframe.values\n",
        "  data = dataset[:, 0:55]\n",
        "  scaler = MinMaxScaler()\n",
        "  data = scaler.fit_transform(data)\n",
        "\n",
        "  nb_set = 50000\n",
        "  nb_test = int(nb_set*0.8)\n",
        "  x_train = data[:nb_test,0:50]\n",
        "  x_test  = data[nb_test:,0:50]\n",
        "  print(np.shape(x_train))\n",
        "  print('x_train = ', x_train)\n",
        "\n",
        "  y_train = data[:nb_test,50:55]\n",
        "  y_test  = data[nb_test:,50:55]\n",
        "  print(np.shape(y_train))\n",
        "  print('y_train = ',y_train)\n",
        "\n",
        "  x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
        "\n",
        "  input_node  = x_train.shape[1]\n",
        "  output_node = y_train.shape[1]\n",
        "  n_timesteps = x_train.shape[2]\n",
        "\n",
        "  agrs = [input_node, n_timesteps, output_node, x_train, y_train,x_test, y_test]\n",
        "\n",
        "      # # Parallel run with Process\n",
        "  p1 = mp.Process(target=LSTM_1, args=agrs)\n",
        "  p2 = mp.Process(target=LSTM_2, args=agrs)\n",
        "  p3 = mp.Process(target=LSTM_3, args=agrs) \n",
        "  p4 = mp.Process(target=LSTM_4, args=agrs)\n",
        "  p5 = mp.Process(target=LSTM_5, args=agrs)\n",
        "  p6 = mp.Process(target=LSTM_6, args=agrs)\n",
        "  p7 = mp.Process(target=LSTM_7, args=agrs)\n",
        "  # p8 = mp.Process(target=LSTM_8, args=agrs)\n",
        "  # p9 = mp.Process(target=LSTM_9, args=agrs)\n",
        "  # p10 = mp.Process(target=LSTM_10, args=agrs)\n",
        "\n",
        "  p1.start()\n",
        "  p2.start()\n",
        "  p3.start()\n",
        "  p4.start()\n",
        "  p5.start()\n",
        "  p6.start()\n",
        "  p7.start()\n",
        "  # p8.start()\n",
        "  # p9.start()\n",
        "  # p10.start()\n",
        "\n",
        "\n",
        "\n",
        "  p1.join()\n",
        "  p2.join()\n",
        "  p3.join()\n",
        "  p4.join()\n",
        "  p5.join()\n",
        "  p6.join()\n",
        "  p7.join()\n",
        "  # p8.join()\n",
        "  # p9.join()\n",
        "  # p10.join()\n",
        "\n",
        "  stop = timeit.default_timer()\n",
        "  Time = stop - start\n",
        "  print('Time = ', Time)\n",
        "\n",
        "  f = open('/content/drive/MyDrive/Research/Deep Learning/LSTM/Total_Computational_Time.txt', 'w')\n",
        "  s = str(Time)\n",
        "  f.write(s)\n",
        "  f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}